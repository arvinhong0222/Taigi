{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torchaudio\n",
    "import jiwer\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from data_collator_ctc import DataCollatorCTCWithPadding, EvalDataCollatorCTCWithPadding  # 請確認檔案名稱正確"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 1. 系統與硬體設定\n",
    "# ===========================\n",
    "# 使用 GPU 2 與 GPU 3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 2. 模型與資料路徑設定\n",
    "# ===========================\n",
    "MODEL_NAME = \"../sslab_model/whisper-large-zh-cv11\"\n",
    "DATA_PATH = \"../sslab_dataset/sutiau-wav\"\n",
    "OUTPUT_DIR = \"./whisper_taiwanese\"\n",
    "AUDIO_PATH = os.path.join(DATA_PATH, \"train\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Data: {DATA_PATH}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")\n",
    "print(f\"Audio: {AUDIO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 3. 載入處理器與模型\n",
    "# ===========================\n",
    "# 使用 WhisperProcessor 並指定語言與任務（例如 translate 或 transcribe）\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME, language=\"zh\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 4. 載入資料集\n",
    "# ===========================\n",
    "data_files = {\n",
    "    \"train\": f\"{DATA_PATH}/train/train.json\",\n",
    "    \"validation\": f\"{DATA_PATH}/val/valid.json\"\n",
    "}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 5. 資料前處理（文本清理）\n",
    "# ===========================\n",
    "def remove_special_characters(batch):\n",
    "    # 這裡使用「漢字」欄位作為標籤文本，依需要也可以改成「羅馬字」\n",
    "    if batch.get(\"漢字\"):\n",
    "        # 移除掉非字詞字符（依需求修改正則表達式）\n",
    "        batch[\"漢字\"] = re.sub(r\"[^\\w\\s]\", \"\", batch[\"漢字\"]).strip()\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 6. 音訊處理與標籤生成\n",
    "# ===========================\n",
    "def speech_file_to_array_fn(batch):\n",
    "    file_path = os.path.join(AUDIO_PATH, batch[\"音檔檔名\"] + \".wav\")\n",
    "    if not os.path.exists(file_path):\n",
    "        # 檔案不存在時，設定為 None（後續會過濾掉這筆資料）\n",
    "        batch[\"input_values\"] = None\n",
    "        batch[\"labels\"] = None\n",
    "        return batch\n",
    "    try:\n",
    "        speech_array, sampling_rate = torchaudio.load(file_path)\n",
    "        if speech_array.ndim > 1:\n",
    "            speech_array = torch.mean(speech_array, dim=0, keepdim=True)\n",
    "        speech_array = speech_array.squeeze().numpy()\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "        speech_tensor = torch.tensor(speech_array)\n",
    "        speech_array = resampler(speech_tensor).squeeze().numpy()\n",
    "        # 處理音訊輸入\n",
    "        batch[\"input_values\"] = processor(speech_array, sampling_rate=16000).input_values[0]\n",
    "        # 使用「漢字」欄位作為標籤；若希望使用羅馬字，請改成 batch[\"羅馬字\"]\n",
    "        batch[\"labels\"] = processor(text=batch[\"漢字\"]).input_ids\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        batch[\"input_values\"] = None\n",
    "        batch[\"labels\"] = None\n",
    "    return batch\n",
    "\n",
    "# 在 map 過程中移除掉不需要的欄位（這邊移除「音檔檔名」）\n",
    "dataset = dataset.map(speech_file_to_array_fn, remove_columns=[\"音檔檔名\"])\n",
    "\n",
    "# 過濾掉標籤或輸入處理失敗的資料\n",
    "dataset = dataset.filter(lambda x: x.get(\"漢字\") is not None and x.get(\"input_values\") is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 7. 數據處理器與評估指標\n",
    "# ===========================\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions.argmax(-1)\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(label_ids)\n",
    "    wer = jiwer.wer(label_str, pred_str)\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 8. 建立抽樣驗證集\n",
    "# ===========================\n",
    "# 對驗證集隨機抽樣 2500 筆（固定 seed 以確保重現性）\n",
    "sampled_eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 9. 訓練參數設定（訓練在 GPU 上）\n",
    "# ===========================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=1,\n",
    "    eval_accumulation_steps=32,    # 每次搬移較小的資料量\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,                # 每 500 個訓練步驟執行一次 eval\n",
    "    save_strategy=\"steps\",\n",
    "    num_train_epochs=5,\n",
    "    save_steps=1000,                # 每 500 步存一次 checkpoint\n",
    "    logging_steps=100,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.005,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    dataloader_num_workers=16,\n",
    "    optim=\"adamw_torch\",\n",
    "    ddp_find_unused_parameters=True,\n",
    "    gradient_checkpointing=False,\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_drop_last=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=sampled_eval_dataset,  # 使用抽樣驗證集\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "last_checkpoint = get_last_checkpoint(OUTPUT_DIR)\n",
    "if last_checkpoint is not None:\n",
    "    print(f\"發現 checkpoint: {last_checkpoint}，將從 checkpoint 恢復訓練。\")\n",
    "    # 清理 GPU 記憶體\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "else:\n",
    "    print(\"未發現有效 checkpoint，將正常開始訓練。\")\n",
    "    # 清理 GPU 記憶體\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taigi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
